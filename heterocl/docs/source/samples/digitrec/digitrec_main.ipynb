{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nHeteroCL Tutorial : K-Nearest-Neighbor Digit Recognition\n========================================================\n\n**Author**: Yi-Hsiang Lai (seanlatias@github)\n\nHeteroCL is a domain-specific language (DSL) based on TVM that supports\nheterogeneous backend devices. Moreover, HeteroCL also supports imperative\nprogramming and bit-accurate data types. This tutorials demonstrates how to\nimplement KNN-based digit recognition in HeteroCL.\n\nDigit recognition is wildly used in many fields, such as automotives.\nDespite the fact that most digit recognition algorithms rely on deep learning,\nhere we simply use the KNN-based algorithm. The input is a 7x7 black and white\nimage, which are encoded to 1 and 0, respectively. After we have the input test\nimage, we perform bitwise XOR with all training images. We then calculate the\nnumber of ones for each XOR result. To make the above process easier, we\nflatten each 7x7 image to a 49-bit integer, which makes the bitwise XOR faster.\nWe called the results of number of ones \"distance\". Our goal is to find the\ndigit with the smallest distance. In this tutorial, we set K to 3. Namely, for\neach digit we will have three candidates. After that, we perform voting\naccording to the candidates. The winner will be the final label we predict. To\nsum up, we can use the following data flow graph to illustrate the whole\nprocess.\n\n.. code-block:: none\n\n    +----------------------+     +--------------------------------------------+\n    | 49-bit testing image | xor | 49-bit training images (10 classes x 1800) |\n    +----------------------+     +--------------------------------------------+\n                              |\n                              V\n              +--------------------------------+\n              | 49-bit diff shape = (10, 1800) |\n              +--------------------------------+\n                              |  popcount\n                              V\n                +-----------------------------+    +-------------------------+\n                | distance shape = (10, 1800) |    | knn_mat shape = (10, 3) |\n                +-----------------------------+    +-------------------------+\n                              |                                 |\n                              +---------------------------------+\n                                              | update knn_mat\n                                              V\n                               +--------------------------------+\n                               | updated knn_mat shape = (10,3) |\n                               +--------------------------------+\n                                              | vote\n                                              V\n                                      +--------------+\n                                      | label (0~10) |\n                                      +--------------+\n\nIn this tutorial, we assume that we want to offload every operation before\nvoting to FPGA. We create a top function for that accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import necessary modules.\nimport heterocl as hcl\nimport time\nimport numpy as np\nimport math\nfrom digitrec_data import read_digitrec_data\n\n# Declare some constants and data types. For images, we need unsigned 49-bit\n# integers, while for knn matrices, we need unsigned 6-bit integers.\nN = 7 * 7\nmax_bit = int(math.ceil(math.log(N, 2)))\ndata_size = (10, 1800)\n\n# HeteroCL provides users with a set of bit-accurate data types, which include\n# unsigned/signed arbitrary-bit integers and unsigned/signed fixed-points.\n# Here we use `UInt(N)` for an N-bit unsigned integer.\ndtype_image = hcl.UInt(N)\ndtype_knnmat = hcl.UInt(max_bit)\n\n# We can initialize a HeteroCL environment with default data type by using\n# `hcl.init(dtype)`. Here we set the default data type of each variable to\n# the unsigned integer with the maximum bitwidth.\nhcl.init(dtype_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Top Function Offloaded to FPGA\n==============================\nFollowing we show the code first. For each code block, you can find a\ncorresponding explanation at the end of the top function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def top(target=None):\n\n    # Algorithm definition (\u00a71)\n    def knn(test_image, train_images):\n\n        # Imperative programming and bit operations (\u00a72)\n        def popcount(num):\n            out = hcl.local(0, \"out\")\n            with hcl.for_(0, train_images.type.bits) as i:\n                # Bit selection operation\n                out[0] += num[i]\n            return out[0]\n\n        # This function update the candidates, i.e., `knn_mat`. Here we mutate\n        # through the shape of tensor `dist`. For each `dist` value, if it is\n        # smaller than the maximum candidate, we replace it.\n        def update_knn(dist, knn_mat, i, j):\n            max_id = hcl.local(0, \"max_id\")\n            with hcl.for_(0, 3) as k:\n                with hcl.if_(knn_mat[i][k] > knn_mat[i][max_id[0]]):\n                    max_id[0] = k\n            with hcl.if_(dist[i][j] < knn_mat[i][max_id[0]]):\n                knn_mat[i][max_id[0]] = dist[i][j]\n\n        # Main algorithm (\u00a73)\n        # Fist step: XOR (\u00a73.1)\n        diff = hcl.compute(train_images.shape,\n                           lambda x, y: train_images[x][y] ^ test_image,\n                           \"diff\")\n\n        # Second step: popcount (\u00a73.2)\n        dist = hcl.compute(diff.shape,\n                           lambda x, y: popcount(diff[x][y]),\n                           \"dist\")\n\n\n        # Third step: initialize the candidates (\u00a73.3)\n        knn_mat = hcl.compute((10, 3), lambda x, y: 50, \"knn_mat\")\n\n\n        # Fourth step: update the candidates (\u00a73.4)\n        hcl.mutate(dist.shape,\n                        lambda x, y: update_knn(dist, knn_mat, x, y),\n                        \"knn_update\")\n\n        # Final step: return the candidates (\u00a73.5)\n        return knn_mat\n\n    # Inputs/Outputs definition (\u00a74)\n    # Scalars (\u00a74.1)\n    test_image = hcl.placeholder((), \"test_image\")\n    # Tensors (\u00a74.2)\n    train_images = hcl.placeholder(data_size, \"train_images\")\n\n    # Data type customization (\u00a75.1)\n    scheme = hcl.create_scheme([test_image, train_images], knn)\n    scheme.downsize([knn.dist, knn.dist.out, knn.knn_mat], dtype_knnmat)\n\n    # Compute customization (\u00a75.2)\n    s = hcl.create_schedule_from_scheme(scheme)\n\n    diff = knn.diff\n    dist = knn.dist\n    knn_update = knn.knn_update\n\n    # Merge loop nests\n    s[diff].compute_at(s[dist], dist.axis[1])\n    s[dist].compute_at(s[knn_update], knn_update.axis[1])\n\n    # Reorder loop to expose more parallelism\n    s[knn_update].reorder(knn_update.axis[1], knn_update.axis[0])\n\n    # Parallel outer loop and pipeline inner loop\n    s[knn_update].parallel(knn_update.axis[1])\n    s[knn_update].pipeline(knn_update.axis[0])\n\n    # At the end, we build the whole offloaded function.\n    return hcl.build(s, target=target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Algorithm Definition\n-----------------------\nIn HeteroCL, we define the algorithm in a separate function call. The\narguments are the inputs/outputs. We can also return computed outputs at\nthe end of the function call. Following we explain the code part by part.\n\n2. Imperative Programming and Bit Operations\n--------------------------------------------\nThis function calculate the number of ones of a 49-bit unsigned integer.\nHere we demonstrate that HeteroCL supports imperative code. All variables\ndeclared within the block will live in corresponding scope. In this function,\n`out` is an intermediate variable with initial value 0. Since we already set\nthe default data type, the data type for `out` is `UInt(N)`. This function\nalso shows the capability of bit operations.\n\n3. Main Algorithm\n-----------------\n\n3.1 First Step: XOR\n~~~~~~~~~~~~~~~~~~~\nThis is the first step of our algorithm. Namely, compute the XOR of a test\nimage with a set of training images. In other words,\n\n`diff[x][y] = train_images[x][y] ^ test_image`,\n\nfor all x and y in shape `(10, N)`.\n\nWe can use \"hcl.compute\" to achieve the above computation. This API is\ndeclarative. Namely, we only specify the results we want, without explicitly\nwriting how the results should be computed.\n\n`A = hcl.compute(shape, fcompute, name, dtype)`\n\nThe first field is the shape; the second field is a lambda function that\ncomputes the results for each element of the output tensor. Without applying\nany scheduling function, the code is equivalent to\n\n.. code-block:: python\n\n    for x in range(0, 10):\n       for y in range(0, 1800):\n           diff[x][y] = train_images[x][y] ^ test_image\n\nIt is optional for users to specify the name and output data type. Here we\ndo not specify the data type, since by default it is UInt(49).\n\n3.2 Second Step: Popcount\n~~~~~~~~~~~~~~~~~~~~~~~~~\nOur next step is to calculate the number of ones for each value in diff.\nThis is where we call the function `popcount`. Since what we want to do here\nis similar to the XOR operation above, we can again use `hcl.compute`. Since\nthe maximum difference is 49, we only need 6-bit unsigned integers. Here we\ndo not specify the data type. We will use \"downsize\" later.\n\n3.3 Third Step: Initialize the Candidates\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nThe next step is to compute the candidates. In our algorithm, we find the\nmaximum candidate and replace it if the new incoming value is smaller. Thus,\nwe initialize the value of the candidate tensor with 50, which is larger\nthan the maximum possible distance: 49. To initialize a tensor we can use\nstill use \"hcl.compute\" API.\n\n3.4 Fourth step: Update the Candidates\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nFinally, we update our candidate. Here we can no longer use `hcl.compute`\nbecause we do not update the candidates one by one sequentially. Thus, we\nuse another API called `mutate`, which compute the lambda function\nfor a given mutation domain. The code is equivalent to the following\nPython code.\n\n`hcl.mutate(domain, fcompute, name)`\n\n.. code-block:: python\n\n    for x in range(0, 10):\n        for y in range(0, 1800):\n            update_knn(dist, knn_mat, x, y)\n\nThe interface is almost the same as `hcl.compute`. The only differences are:\n1. the shape is the mutation domain instead of the output shape.\n2. since we do not return any new output function, there is no field for the\ndata type.\n3. There is no output for this API.\n\n3.5 Final step: Return the Candidates\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nWe need to return the updated candidates as our final output tensor.\n\n4. Inputs/Outputs Definition\n----------------------------\n\n4.1 Scalars\n~~~~~~~~~~~\nTo specify an input scalar, we use `hcl.var`. We can specify the name and\ndata type of the it.\n\n`a = hcl.var(name, dtype)`\n\nHere the variable is the test image we want to classify. The data type is by\ndefault `UInt(49)`.\n\n4.2 Tensors\n~~~~~~~~~~~\nTo specify an input tensor, we use `hcl.placeholder`.\n\n`A = hcl.placeholder(shape, name, dtype)`\n\nThe first field is the shape of the tensor. It is optional for users to set\nthe name and data type. Here the data type is again UInt(49).\n\n5. Customization Primitives\n---------------------------\n\n5.1 Data Type Customization (Quantization)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nThis is another feature of HeteroCL, which allows users to quantize/downsize\nthe data type of variables independent of the algorithm specification. We can\ndownsize a set of inputs, which can be a tensor or a scalar. Here, we apply\nthe corresponding data type as we mentioned in the previous steps. Note that\n`downsize` is used for integers only.\n\n5.2 Compute Customization\n~~~~~~~~~~~~~~~~~~~~~~~~~\nHere we can describe how we want the loops to be scheduled or transformed for\nhardware optimization. The first thing we can do is merge the loops together.\nThis first provides better data locality and thus exposes more parallelism.\nWe can merge the loops by using `compute_at`. Here we show how it works.\n\n.. code-block:: none\n\n    produce A {\n        loop_1 {\n            body_A\n        }\n    }\n    produce B {\n        loop_1 {\n            body_B\n        }\n    }\n\nSince we have a common loop in both stage A and B, we can use `compute_at` to\nmerge them.\n\n`s[A].compute_at(s[B], loop_1)`\n\nThis is the equivalent result.\n\n.. code-block:: none\n\n    produce B {\n        loop_1 {\n            produce A {\n                body_A\n            }\n            body_B\n        }\n    }\n\nWe can then apply loop parallelisms primitives such as pipelining and\nparallel.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Main function\n=============\nThis is the main function. Namely, the complete algorithm we want to run. We\nget the offloaded function with the provided data types\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "offload = top()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Voting algorithm\n----------------\nThis function implements the voting algorithm. We first sort for each digit.\nAfter that, we compare the values of the first place in each digit. The digit\nwith the shortest value get one point. Similarly, we give the point to digits\naccording to their ranking for the second place and third place. Finally, we\ntake the digit with the highest point as our prediction label.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def knn_vote(knn_mat):\n    knn_mat.sort(axis = 1)\n    knn_score = np.zeros(10)\n\n    for i in range(0, 3):\n        min_id = np.argmin(knn_mat, axis = 0)[i]\n        knn_score[min_id] += 1\n\n    return np.argmax(knn_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the Results\n---------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Data preparation\ntrain_images, _, test_images, test_labels = read_digitrec_data()\n\n# Classification and testing\ncorrect = 0.0\n\n# We have 180 test images\ntotal_time = 0\nfor i in range(0, 180):\n\n    # Prepare input data to offload function\n    # To load the tensors into the offloaded function, we must first cast it to\n    # the correct data type.\n    hcl_train_images = hcl.asarray(train_images, dtype_image)\n    hcl_knn_mat = hcl.asarray(np.zeros((10, 3)), dtype_knnmat)\n\n    # Execute the offload function and collect the candidates\n    start = time.time()\n    offload(test_images[i], hcl_train_images, hcl_knn_mat)\n    total_time = total_time + (time.time() - start)\n\n    # Convert back to a numpy array\n    knn_mat = hcl_knn_mat.asnumpy()\n\n    # Feed the candidates to the voting algorithm and compare the labels\n    if knn_vote(knn_mat) == test_labels[i]:\n        correct += 1\n\nprint(\"Average kernel time (s): {:.2f}\".format(total_time/180))\nprint(\"Accuracy (%): {:.2f}\".format(100*correct/180))\n\n# for testing\nassert (correct >= 150.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}