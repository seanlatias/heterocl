{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nHeteroCL Tutorial : LeNet Inference\n===================================\n\n**Author**: Yi-Hsiang Lai (seanlatias@github)\n\nBuild the LeNet inference model by using hlib. In this tutorial, we demonstrate\nhow we can apply inference-time quantization to an existing model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import heterocl as hcl\nimport hlib\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially we let every operation to be a floating-point operation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hcl.init(hcl.Float())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can define your own layer without using the one provided in hlib\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def softmax(out, x):\n    assert len(x.shape) == 2, \"only support 2-dim softmax\"\n    m, n = x.shape\n    k = hcl.reduce_axis(0, n)\n    max_elem = hcl.compute((m,), lambda i: hcl.max(x[i, k], axis=k))\n    k = hcl.reduce_axis(0, n)\n    expsum = hcl.compute((m,),\n            lambda i: hcl.sum(hcl.exp(x[i, k] - max_elem[i]), axis=k))\n    return hcl.update(out,\n            lambda i, j: hcl.exp(x[i, j] - max_elem[i]) / expsum[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The main function for build the LeNet inference model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def build_lenet(input_image, weight_conv1, weight_conv2,\n                weight_fc1, weight_fc2, lenet):\n    # first conv\n    conv1 = hlib.nn.conv2d_nchw(input_image, weight_conv1)\n    tanh1 = hlib.nn.tanh(conv1, \"tanh1\")\n    pool1 = hlib.nn.max_pool(tanh1, kernel=(2,2), stride=(2,2))\n    # second conv\n    conv2 = hlib.nn.conv2d_nchw(pool1, weight_conv2)\n    tanh2 = hlib.nn.tanh(conv2, \"tanh2\")\n    pool2 = hlib.nn.max_pool(tanh2, kernel=(2,2), stride=(2,2))\n    # first fc\n    flat = hlib.nn.flatten(pool2)\n    fc1 = hlib.nn.dense(flat, weight_fc1)\n    tanh3 = hlib.nn.tanh(fc1, \"tanh3\")\n    # second fc\n    fc2 =  hlib.nn.dense(tanh3, weight_fc2)\n    # loss\n    return softmax(lenet, fc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the dataset from mxnet\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mxnet as mx\n# download pretrained lenet model\nmx.gluon.utils.download('https://gist.githubusercontent.com/Huyuwei/dc00ce83f537914c64a204133d23b019/raw/79af41e7c8ba9120ea7f35fb1d0484b65bccd54f/lenet-0010.params')\nmx.gluon.utils.download('https://gist.githubusercontent.com/Huyuwei/dc00ce83f537914c64a204133d23b019/raw/79af41e7c8ba9120ea7f35fb1d0484b65bccd54f/lenet-symbol.json')\nsym, arg_params, aux_params = mx.model.load_checkpoint('lenet', 10)\n# get weights\nweight_conv1_np = arg_params['convolution0_weight'].asnumpy()\nweight_conv2_np = arg_params['convolution1_weight'].asnumpy()\nweight_fc1_np = arg_params['fullyconnected0_weight'].asnumpy()\nweight_fc2_np = arg_params['fullyconnected1_weight'].asnumpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the quantized data type and run the inference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qtype1 = hcl.Fixed(16, 14)\nqtype2 = hcl.Fixed(16, 14)\ncorrect_sum = 0\nbatch_size = 1000\nmnist = mx.test_utils.get_mnist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we quantize the weights to `qtype1` and the activations to\n`qtype2`. To quantize the placeholders, simply specify the `dtype` field. For\nthe internal tensors, we use `hcl.quantize` API.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def build_lenet_inf(batch_size=batch_size, target=None):\n    # set up input/output placeholders\n    input_image = hcl.placeholder((batch_size, 1, 28, 28), \"input_image\")\n    weight_conv1 = hcl.placeholder((20, 1, 5, 5), \"weight_conv1\", qtype1)\n    weight_conv2 = hcl.placeholder((50, 20, 5, 5), \"weight_conv2\", qtype1)\n    weight_fc1 = hcl.placeholder((500, 800), \"weight_fc1\", qtype1)\n    weight_fc2 = hcl.placeholder((10, 500), \"weight_fc2\", qtype1)\n    lenet = hcl.placeholder((batch_size, 10), \"lenet\")\n    # create a quantization scheme\n    scheme = hcl.create_scheme(\n            [input_image, weight_conv1, weight_conv2,\n             weight_fc1, weight_fc2, lenet], build_lenet)\n    # quantize the three activation layers\n    scheme.quantize(\n            [build_lenet.tanh1, build_lenet.tanh2, build_lenet.tanh3], qtype2)\n    s = hcl.create_schedule_from_scheme(scheme)\n    return hcl.build(s, target=target)\n\nf = build_lenet_inf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the numpy arrays for testing. Remember that we need to set the input\ntensors with the same type as the placeholders\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weight_conv1_hcl = hcl.asarray(weight_conv1_np, dtype=qtype1)\nweight_conv2_hcl = hcl.asarray(weight_conv2_np, dtype=qtype1)\nweight_fc1_hcl = hcl.asarray(weight_fc1_np, dtype=qtype1)\nweight_fc2_hcl = hcl.asarray(weight_fc2_np, dtype=qtype1)\n\nfor i in range(10000 // batch_size):\n    label = mnist['test_label'][i*batch_size:(i+1)*batch_size]\n    input_image_np = mnist['test_data'][i*batch_size:(i+1)*batch_size]\n    input_image_hcl = hcl.asarray(input_image_np)\n    output_hcl = hcl.asarray(np.zeros((batch_size,10)))\n    f(input_image_hcl, weight_conv1_hcl, weight_conv2_hcl,\n            weight_fc1_hcl, weight_fc2_hcl, output_hcl)\n    prediction = np.argmax(output_hcl.asnumpy(), axis=1)\n    correct_sum += np.sum(np.equal(prediction, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Testing accuracy: {}\".format(correct_sum / 10000.))\n\n# remove downloaded files\nimport os\nos.remove(\"t10k-images-idx3-ubyte.gz\")\nos.remove(\"t10k-labels-idx1-ubyte.gz\")\nos.remove(\"train-images-idx3-ubyte.gz\")\nos.remove(\"train-labels-idx1-ubyte.gz\")\nos.remove(\"lenet-0010.params\")\nos.remove(\"lenet-symbol.json\")\n\nassert correct_sum == 9882"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}